# Object Detection for classifying recycling item  

## 1. Introduction

ë°”ì•¼íë¡œ ëŒ€ëŸ‰ ìƒì‚°, ëŒ€ëŸ‰ ì†Œë¹„ì˜ ì‹œëŒ€. ìš°ë¦¬ëŠ” ë§ì€ ë¬¼ê±´ì´ ëŒ€ëŸ‰ìœ¼ë¡œ ìƒì‚°ë˜ê³ , ì†Œë¹„ë˜ëŠ” ì‹œëŒ€ë¥¼ ì‚´ê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ëŸ¬í•œ ë¬¸í™”ëŠ” 'ì“°ë ˆê¸° ëŒ€ë€', 'ë§¤ë¦½ì§€ ë¶€ì¡±'ê³¼ ê°™ì€ ì—¬ëŸ¬ ì‚¬íšŒ ë¬¸ì œë¥¼ ë‚³ê³  ìˆìŠµë‹ˆë‹¤.  
ë¶„ë¦¬ìˆ˜ê±°ëŠ” ì´ëŸ¬í•œ í™˜ê²½ ë¶€ë‹´ì„ ì¤„ì¼ ìˆ˜ ìˆëŠ” ë°©ë²• ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ì˜ ë¶„ë¦¬ë°°ì¶œ ëœ ì“°ë ˆê¸°ëŠ” ìì›ìœ¼ë¡œì„œ ê°€ì¹˜ë¥¼ ì¸ì •ë°›ì•„ ì¬í™œìš©ë˜ì§€ë§Œ, ì˜ëª» ë¶„ë¦¬ë°°ì¶œ ë˜ë©´ ê·¸ëŒ€ë¡œ íê¸°ë¬¼ë¡œ ë¶„ë¥˜ë˜ì–´ ë§¤ë¦½ ë˜ëŠ” ì†Œê°ë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.  
ë”°ë¼ì„œ ìš°ë¦¬ëŠ” ì‚¬ì§„ì—ì„œ ì“°ë ˆê¸°ë¥¼ Detection í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ì–´ ì´ëŸ¬í•œ ë¬¸ì œì ì„ í•´ê²°í•´ë³´ê³ ì í•©ë‹ˆë‹¤. ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ë°ì´í„°ì…‹ìœ¼ë¡œëŠ” ì¼ë°˜ ì“°ë ˆê¸°, í”Œë¼ìŠ¤í‹±, ì¢…ì´, ìœ ë¦¬ ë“± 10 ì¢…ë¥˜ì˜ ì“°ë ˆê¸°ê°€ ì°íŒ ì‚¬ì§„ ë°ì´í„°ì…‹ì´ ì œê³µë©ë‹ˆë‹¤.  
ì—¬ëŸ¬ë¶„ì— ì˜í•´ ë§Œë“¤ì–´ì§„ ìš°ìˆ˜í•œ ì„±ëŠ¥ì˜ ëª¨ë¸ì€ ì“°ë ˆê¸°ì¥ì— ì„¤ì¹˜ë˜ì–´ ì •í™•í•œ ë¶„ë¦¬ìˆ˜ê±°ë¥¼ ë•ê±°ë‚˜, ì–´ë¦°ì•„ì´ë“¤ì˜ ë¶„ë¦¬ìˆ˜ê±° êµìœ¡ ë“±ì— ì‚¬ìš©ë  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤. ë¶€ë”” ì§€êµ¬ë¥¼ ìœ„ê¸°ë¡œë¶€í„° êµ¬í•´ì£¼ì„¸ìš”! ğŸŒ  

Input : ì“°ë ˆê¸° ê°ì²´ê°€ ë‹´ê¸´ ì´ë¯¸ì§€ì™€ bbox ì •ë³´(ì¢Œí‘œ, ì¹´í…Œê³ ë¦¬)ê°€ ëª¨ë¸ì˜ ì¸í’‹ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤. bbox annotationì€ COCO formatìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤.
Output : ëª¨ë¸ì€ bbox ì¢Œí‘œ, ì¹´í…Œê³ ë¦¬, score ê°’ì„ ë¦¬í„´í•©ë‹ˆë‹¤. ì´ë¥¼ submission ì–‘ì‹ì— ë§ê²Œ csv íŒŒì¼ì„ ë§Œë“¤ì–´ ì œì¶œí•©ë‹ˆë‹¤.

![trash with bbox](images/trash_with_bbox.png)


## 2. Dataset

**ì¬í™œìš© ì“°ë ˆê¸° ë°ì´í„°ì…‹ / Aistages(Upstage) - CC BY 2.0**  

- ì „ì²´ ì´ë¯¸ì§€ ê°œìˆ˜: 9754ì¥
- 10 class: General trash, Paper, Paper pack, Metal, Glass, Plastic, Styrofoam, Plastic bag, Battery, Clothing
- ì´ë¯¸ì§€ í¬ê¸°: (1024, 1024)

### Get Dataset

```
wget https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000076/data/data.tar.gz
```

### Class Description
| class | trash |
|---|:-------------:|
| 0 | General trash |
| 1 | Paper         |
| 2 | Paper pack    |
| 3 | Metal         |
| 4 | Glass         |
| 5 | Plastic       |
| 6 | Styrofoam     |
| 7 | Plastic bag   |
| 8 | Battery       |
| 9 | Clothing      |

### Dataset folder path
```
 dataset
 â”œâ”€â”€ train.json
 â”œâ”€â”€ test.json
 â”œâ”€â”€ train
 â””â”€â”€ test
```

## 3. Prerequisites

### Dependencies
* albumentations==1.0.3
* pycocotools==2.0.2
* opencv-python==4.5.3.56
* tqdm==4.62.3
* torchnet==0.0.4
* pandas==1.3.3
* map-boxes==1.0.5
* pytorch==1.7.1
* [Swin Transformer for Object Detection](https://github.com/SwinTransformer/Swin-Transformer-Object-Detection)
* [UniverseNet](https://github.com/shinya7y/UniverseNet)
* [EfficientDet (PyTorch)](https://github.com/rwightman/efficientdet-pytorch)
* [Yolo5](https://github.com/ultralytics/yolov5/)
* [YOloX](https://github.com/Megvii-BaseDetection/YOLOX/blob/main/setup.py)

### Library getting_started
* [Swin Transformer for Object Detection get_started](https://github.com/open-mmlab/mmdetection/blob/master/docs/get_started.md)
* [UniverseNet get_started](https://github.com/shinya7y/UniverseNet/blob/master/docs/get_started.md)
* [EfficientDet (PyTorch)](https://github.com/rwightman/efficientdet-pytorch#environment-setup)
* [Yolo5](https://github.com/boostcampaitech2/object-detection-level2-cv-19/blob/jsg_yolo5/yolov5/README_original.md#quick-start-examples)
* [YoloX](https://github.com/Megvii-BaseDetection/YOLOX#quick-start)
)

### Quick mmdetection-based library installation in Ustage Object Detecction server 
* mmdetection ê³„ì—´ì´ ì´ë¯¸ ê¹”ë ¤ìˆëŠ” ì„œë²„í™˜ê²½ì—ì„œ ë¹ ë¥´ê²Œ ë‹¤ë¥¸ ë²„ì „ì˜ mmdetection-based libraryë¥¼ ì„¤ì¹˜ í•  ìˆ˜ ìˆë‹¤.
* upstage level2 p-stage object detection ì„œë²„ ì‚¬ìš©ì‹œ ê¸°ì¡´ í™˜ê²½ì„ í´ë¡ í•œ í™˜ê²½ì„ ë§Œë“ ë‹¤.
```
conda create --name detection_custom --clone detection  # í™˜ê²½ì´ ì„¤ì¹˜ë˜ì–´ìˆëŠ” detection ê°€ìƒí™˜ê²½ì„ í´ë¡ 
conda activate detection_custom
```
* mmdetection-based library installation
    * mmdetectionì„ ê¸°ë°˜ìœ¼ë¡œí•œ Swin Transformer for Object Detection ì„¤ì¹˜ ì˜ˆì‹œ
```
# Swin Transformer for Object Detection ì„¤ì¹˜
# https://github.com/SwinTransformer/Swin-Transformer-Object-Detection
git clone https://github.com/SwinTransformer/Swin-Transformer-Object-Detection.git
cd Swin-Transformer-Object-Detection
pip install -r requirements/build.txt
pip install -v -e .
cd ..
# (optional) Apexì„¤ì¹˜
git clone https://github.com/NVIDIA/apex
cd apex
pip install -v --disable-pip-version-check --no-cache-dir ./
cd ..
```

## 4. Pipeline

![pipline](images/pipeline.png)

<br>

### Stage 1: Train individual models

| Model | mAP@50 |
|---|:-------------:|
| [Swin-Transformer-Object-Detection](./Swin-Transformer-Object-Detection/README.md)| Swin-B: 0.645 / Swin-L: 0.666   |
| [YoloV5](yolov5/README.md)                                                        | yolo5l6: 0.620 / yolo5x6: 0.621 |
| [EfficientDet (PyTorch)](efficientdet-pytorch/README.md)                          | D4_ap: 0.602 / D5_ap: 0.594     |
| [UniverseNet](./UniverseNet/README.md)                                            | 0.567                           |
| [YolovX](yolox/README.md)                                                         | 0.548                           |

<br>

### Stage 2: Ensemble model and Pseudo label

 a. Put inferenced json files in `ensemble/results`

```
 ensemble
 â”œâ”€â”€ ensemble.py
 â””â”€â”€ results
     â””â”€â”€ result_swin.json
     â””â”€â”€ result_yolo.json
     â””â”€â”€ ...
     â””â”€â”€ weights.txt
```

 b. write weights.txt
 
```
result_swin 1.2
result_yolo 1.2
...
```

 c. Ensemble results
 
 ```
 cd ensemble
 python ensemble.py --json_path ../dataset/train.json`
 ```
 
 d. Make pseudo labled json file
 
 ```
 cd ../pseudo_labeling
 python make_pseudo_dataset.py --train_json_path ../dataset/train.json --test_json_path ../dataset/test.json --result_json_path ../ensemble/ensembled_result.json`
 ```
 
| Combinations | mAP@50 |
|---|:-------------:|
| Swin-L x 2| 0.687|
| Swin-L + yolo5l6| 0.687|
| Swin-L x 2 + yolo5l6| 0.700|
| Swin-L x 2 + yolo5l6| 0.700|
| Swin-L x 3 + yolo5l6 + effdetD5| 0.707|
| Swin-L x 4 + yolo5l6 + effdetD4 + effdetD5| 0.711|
| Swin-L x 4 + yolo5l6 + yolo5x6 + effdetD4 + effdetD5| 0.714|

<br>

### Stage 3: Train individual models with Pseudo label

Load weights from Stage1 and train with lower epochs and learning rate.

| Model | mAP@50 without Pseudo Labeling | mAP@50 with Pseudo Labeling |
|---|:-------------:|:-------------:|
| [Swin-Transformer-Object-Detection](./Swin-Transformer-Object-Detection/README.md)| Swin-L: 0.666   | Swin-L: 0.659   |
| [YoloV5](yolov5/README.md)                                                        | yolo5l6: 0.620 / yolo5x6: 0.621 | yolo5l6: 0.639 / yolo5x6: 0.649 |
| [EfficientDet (PyTorch)](efficientdet-pytorch/README.md)                          | D4_ap: 0.602 / D5_ap: 0.594     | D4_ap: 0.639 / D5_ap: 0.642     |

<br>

### Stage 4: Ensemble model and Pseudo label

Same as in Stage2 but use results from Stage3

| Combinations | mAP@50 without Pseudo Labeling | mAP@50 with Pseudo Labeling |
|---|:-------------:|:-------------:|
| Swin-L x 4 + yolo5l6 + yolo5x6 + effdetD4 + effdetD5| 0.714| 0.714|

<br>

### Stage 5: Train Classifier

a. If KFold training

`python kfold.py --json_path /path/to/json_file.json --n_splits 5`

b. Train for each split

- run train_clf.ipynb

c. Inference for each split

- run inference_clf.ipynb

<br>

### Stage 6: Calibrate score

a. put inferenced outputs(\*.pkl) to `clf/results`

```
clf
â”œâ”€â”€ calibrate_score.py
â”œâ”€â”€ ...
â”œâ”€â”€ results
â”‚Â Â  â”œâ”€â”€ split1.pkl
â”‚Â Â  â”œâ”€â”€ split2.pkl
â”‚Â Â  â””â”€â”€ ...
â””â”€â”€ ...
```

b. calibrate scores

`python clf/calibrate_score.py --json_path /path/to/ensembled_result.json`

| Combinations | mAP@50 before calibration | mAP@50 after calibration |
|---|:-------------:|:-------------:|
| Swin-L x 4 + yolo5l6 + yolo5x6 + effdetD4 + effdetD5| 0.714| 0.717|

## 5. Ouput Examples

![results](images/output.gif)

<!-- clf? notebooks? -->
