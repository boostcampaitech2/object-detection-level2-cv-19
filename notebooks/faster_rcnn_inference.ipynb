{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd75793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint\n",
    "import os\n",
    "from mmcv.parallel import MMDataParallel\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c2357-338c-4246-bd89-4fbc0080f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "/distributed_train.sh 1 ../dataset --model efficientdet_d0 --dataset trash -b 16 --amp --lr .008 --sync-bn --opt fusedmomentum --warmup-epochs 1 --model-ema --model-ema-decay 0.9966 --epochs 50 --num-classes 10 --pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edda58ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "cfg = Config.fromfile('work_dirs/swin_pseudo/swinL_w12_ms/swinL_w12_ms_pseudo.py')\n",
    "\n",
    "# root='../dataset/'\n",
    "\n",
    "# epoch = 'latest'\n",
    "\n",
    "# cfg.data.test.classes = classes\n",
    "# cfg.data.test.img_prefix = root\n",
    "# cfg.data.test.ann_file = root + 'test.json' # test json 정보\n",
    "# cfg.data.test.pipeline[1]['img_scale'] = [(512, 512),\n",
    "#  (768, 768),\n",
    "#  (1024, 1024),\n",
    "#  (1280, 1280),\n",
    "#  (1536, 1536),\n",
    "#  (1792, 1792),\n",
    "#  (2048, 2048),\n",
    "#  (2304, 2304),\n",
    "#  (2560, 2560)] # Resize\n",
    "\n",
    "cfg.data.test.test_mode = True\n",
    "\n",
    "# cfg.data.samples_per_gpu = 4\n",
    "\n",
    "# cfg.seed = 2021\n",
    "# cfg.gpu_ids = [1]\n",
    "# cfg.work_dir = './work_dirs/gfl_r50_fpn_mstrain_2x_coco-value'\n",
    "\n",
    "# cfg.model.bbox_head.num_classes = 10\n",
    "\n",
    "# cfg.optimizer_config.grad_clip = dict(max_norm=35, norm_type=2)\n",
    "# cfg.model.train_cfg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b086a8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.13s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# build dataset & dataloader\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83b3eae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "# checkpoint path\n",
    "checkpoint_path = os.path.join(cfg.work_dir, 'latest.pth')\n",
    "\n",
    "model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg')) # build detector\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu') # ckpt load\n",
    "\n",
    "model.CLASSES = dataset.CLASSES\n",
    "model = MMDataParallel(model.cuda(), device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f5c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  ] 0/4871, elapsed: 0s, ETA:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/swin/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>] 4871/4871, 0.3 task/s, elapsed: 18126s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "output = single_gpu_test(model, data_loader, show_score_thr=0.000001) # output 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f738134-21ca-4268-b395-9ed5bf6d385a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 4871, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output), len(output), len(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5672a0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 0.18200925 214.47617 696.4084 251.81688 733....</td>\n",
       "      <td>test/0000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 0.08632532 132.96068 0.66780853 493.2763 276...</td>\n",
       "      <td>test/0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 0.9508363 880.43506 465.57214 1021.6876 629....</td>\n",
       "      <td>test/0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9 0.99566114 151.69984 263.47235 915.5954 813....</td>\n",
       "      <td>test/0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 0.784179 429.02695 406.4891 655.5055 567.256...</td>\n",
       "      <td>test/0004.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    PredictionString       image_id\n",
       "0  0 0.18200925 214.47617 696.4084 251.81688 733....  test/0000.jpg\n",
       "1  0 0.08632532 132.96068 0.66780853 493.2763 276...  test/0001.jpg\n",
       "2  0 0.9508363 880.43506 465.57214 1021.6876 629....  test/0002.jpg\n",
       "3  9 0.99566114 151.69984 263.47235 915.5954 813....  test/0003.jpg\n",
       "4  0 0.784179 429.02695 406.4891 655.5055 567.256...  test/0004.jpg"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submission 양식에 맞게 output 후처리\n",
    "prediction_strings = []\n",
    "file_names = []\n",
    "coco = COCO(cfg.data.test.ann_file)\n",
    "img_ids = coco.getImgIds()\n",
    "\n",
    "class_num = 10\n",
    "for i, out in enumerate(output):\n",
    "    prediction_string = ''\n",
    "    image_info = coco.loadImgs(coco.getImgIds(imgIds=i))[0]\n",
    "    for j in range(class_num):\n",
    "        for o in out[j]:\n",
    "            prediction_string += str(j) + ' ' + str(o[4]) + ' ' + str(o[0]) + ' ' + str(o[1]) + ' ' + str(\n",
    "                o[2]) + ' ' + str(o[3]) + ' '\n",
    "        \n",
    "    prediction_strings.append(prediction_string)\n",
    "    file_names.append(image_info['file_name'])\n",
    "\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "submission.to_csv(os.path.join(cfg.work_dir, f'submission_epoch4.csv'), index=None)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "defea261-b193-4052-802d-5d2e0b9bfca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "[                               ] 10/3906, 3.3 task/s, elapsed: 3s, ETA:  1199s^C\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/misc/browse_dataset.py\", line 96, in <module>\n",
      "    main()\n",
      "  File \"tools/misc/browse_dataset.py\", line 90, in main\n",
      "    text_color=(255, 102, 61))\n",
      "  File \"/opt/conda/envs/detection/lib/python3.7/site-packages/mmdet/core/visualization/image.py\", line 170, in imshow_det_bboxes\n",
      "    stream, _ = canvas.print_to_buffer()\n",
      "  File \"/opt/conda/envs/detection/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\", line 514, in print_to_buffer\n",
      "    FigureCanvasAgg.draw(self)\n",
      "  File \"/opt/conda/envs/detection/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\", line 406, in draw\n",
      "    self.figure.draw(self.renderer)\n",
      "  File \"/opt/conda/envs/detection/lib/python3.7/site-packages/matplotlib/artist.py\", line 74, in draw_wrapper\n",
      "    result = draw(artist, renderer, *args, **kwargs)\n",
      "  File \"/opt/conda/envs/detection/lib/python3.7/site-packages/matplotlib/artist.py\", line 51, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"/opt/conda/envs/detection/lib/python3.7/site-packages/matplotlib/figure.py\", line 2791, in draw\n",
      "    renderer, self, artists, self.suppressComposite)\n",
      "  File \"/opt/conda/envs/detection/lib/python3.7/site-packages/matplotlib/image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/opt/conda/envs/detection/lib/python3.7/site-packages/matplotlib/artist.py\", line 51, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"/opt/conda/envs/detection/lib/python3.7/site-packages/matplotlib/_api/deprecation.py\", line 431, in wrapper\n",
      "    return func(*inner_args, **inner_kwargs)\n",
      "  File \"/opt/conda/envs/detection/lib/python3.7/site-packages/matplotlib/axes/_base.py\", line 2921, in draw\n",
      "    mimage._draw_list_compositing_images(renderer, self, artists)\n",
      "  File \"/opt/conda/envs/detection/lib/python3.7/site-packages/matplotlib/image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"/opt/conda/envs/detection/lib/python3.7/site-packages/matplotlib/artist.py\", line 51, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"/opt/conda/envs/detection/lib/python3.7/site-packages/matplotlib/image.py\", line 641, in draw\n",
      "    renderer, renderer.get_image_magnification())\n",
      "  File \"/opt/conda/envs/detection/lib/python3.7/site-packages/matplotlib/image.py\", line 927, in make_image\n",
      "    magnification, unsampled=unsampled)\n",
      "  File \"/opt/conda/envs/detection/lib/python3.7/site-packages/matplotlib/image.py\", line 552, in _make_image\n",
      "    self, _rgb_to_rgba(A[..., :3]), out_shape, t, alpha=alpha)\n",
      "  File \"/opt/conda/envs/detection/lib/python3.7/site-packages/matplotlib/image.py\", line 198, in _resample\n",
      "    image_obj.get_filterrad())\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python tools/misc/browse_dataset.py ./my_config/cascade_rcnn_swin-l-p4-w7_fpn_1x_coco-384-mixup.py --output-dir augment_test --not-show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f0efa6-68bf-48ad-b29c-44ab148127b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dirs/swin/large_384_lb/cascade_rcnn_swin-l-p4-w7_fpn_1x_coco-384-lb.py\n",
    "work_dirs/swin/large_384_lb/latest.pth\n",
    "work_dirs/swin/large_384_lb/result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42711914-c611-43cc-ad8b-e14817ca327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dirs/faster_rcnn/base_split/best_bbox_mAP_50_epoch_12.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcba0a5-6d12-420d-8f10-f1dc1c447cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection/mmdetection/work_dirs/faster_rcnn/base_split/epoch_10.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d9c0ba-e2e9-449a-ba91-2d2cf0962cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tools/test.py work_dirs/swin/base/cascade_rcnn_swin-s-p4-w7_fpn_1x_coco.py work_dirs/swin/base/best_bbox_mAP_50.pth --eval bbox --out result.pkl --options \"classwise=True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95760600-48db-46fc-a56e-cc67ecbe4d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 977/977, 1.7 task/s, elapsed: 581s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "python tools/analysis_tools/analyze_results.py work_dirs/faster_rcnn/base_split/faster_rcnn_base.py result.pkl work_dirs/faster_rcnn/base_split/result --show-score-thr 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994979e3-5e41-481d-8a6e-1101b8fee434",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tools/test.py work_dirs/swin/large_384_lb/cascade_rcnn_swin-l-p4-w7_fpn_1x_coco-384-lb.py work_dirs/swin/large_384_lb/latest.pth --format-only  --options \"jsonfile_prefix=./results\"\n",
    "python tools/analysis_tools/coco_error_analysis.py results.bbox.json work_dirs/swin/large_384_lb/result --ann=../dataset/val_split.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da71b188-d038-49ed-a13b-21d7f914d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tools/test.py /path/to/config.py /path/to/weight.pth --eval bbox --out result.pkl --options \"classwise=True\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swin",
   "language": "python",
   "name": "swin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
